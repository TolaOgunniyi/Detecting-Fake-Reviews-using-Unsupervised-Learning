{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6A: LDA Topic Modelling\n",
    "\n",
    "In parallel with KMeans Clustering, I also would like to try clustering the review text using LDA Topic Modelling. The key difference between the 2 clustering methods is LDA topic modelling clusters reviews into different topics by solely looking at **text data** which in this case will be the review text. In contrast, KMeans Clustering can cluster the reviews based on **all features**, tokenized text and other numeric features. \n",
    "\n",
    "The goal of this notebook is to perform LDA topic modelling on the review text and compare the results with the clusters formed via KMeans clustering to try and identify fake reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing relevant libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries for text processing\n",
    "from nltk.corpus import stopwords \n",
    "ENGLISH_STOP_WORDS = stopwords.words('english')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bringing in just the reviewText from the dataset (require custom functions library)\n",
    "import functions_library as fl\n",
    "review_text = fl.cleanDF(fl.createPdDF('All_Beauty.json.gz'))['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                     great\n",
       "1         My  husband wanted to reading about the Negro ...\n",
       "2         This book was very informative, covering all a...\n",
       "3         I am already a baseball fan and knew a bit abo...\n",
       "4         This was a good story of the Black leagues. I ...\n",
       "                                ...                        \n",
       "362247    It was awful. It was super frizzy and I tried ...\n",
       "362248    I was skeptical about buying this.  Worried it...\n",
       "362249                             Makes me look good fast.\n",
       "362250    Way lighter than photo\\nNot mix blend of color...\n",
       "362251    No return instructions/phone # in packaging.  ...\n",
       "Name: reviewText, Length: 362252, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure it's loaded in properly\n",
    "review_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using same settings used for KMeans clustering to be consistent\n",
    "vectorizer = TfidfVectorizer(min_df = 1000, tokenizer = fl.spl_tokenizer, ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tokens from reviewText\n",
    "word_matrix = vectorizer.fit_transform(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\\\n",
    "#source: https://github.com/kapadias/mediumposts/blob/master/nlp/published_notebooks/Introduction%20to%20Topic%20Modeling.ipynb\n",
    "def print_topics(model, vectorizer, n_top_words):\n",
    "    words = vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\",\".join([words[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Topic Modelling with 25 Topics\n",
    "For LDA topic Modelling, we need to pre-select the number of topics we think exist in our text. To be consistent with KMeans clustering, I will choose 25 topics as we had selected 25 clusters for KMeans. Note: this is not necessarily the optimal way to determine the number of topics. Can make improvements in future iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting number of topics and also the top number of words we want to see from the model\n",
    "number_topics = 25\n",
    "number_words = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n",
      "iteration: 2 of max_iter: 10\n",
      "iteration: 3 of max_iter: 10\n",
      "iteration: 4 of max_iter: 10\n",
      "iteration: 5 of max_iter: 10\n",
      "iteration: 6 of max_iter: 10\n",
      "iteration: 7 of max_iter: 10\n",
      "iteration: 8 of max_iter: 10\n",
      "iteration: 9 of max_iter: 10\n",
      "iteration: 10 of max_iter: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=25, n_jobs=4,\n",
       "                          perp_tol=0.1, random_state=None,\n",
       "                          topic_word_prior=None, total_samples=1000000.0,\n",
       "                          verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit the LDA model\n",
    "lda = LDA(n_components=number_topics, n_jobs=4, verbose=1)\n",
    "lda.fit(word_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found via LDA:\n",
      "\n",
      "Topic #0:\n",
      "brush,perfectly,stand,hold,great,sturdy,nice,look,fit,well,look great,razor,bristle,handle,set\n",
      "\n",
      "Topic #1:\n",
      "cute,nail,polish,happy,super,every,working,coat,love,compliment,color,day,nail polish,wear,use\n",
      "\n",
      "Topic #2:\n",
      "blade,razor,shave,year,sharp,shaving,old,close,cut,get,year old,one,electric,gillette,use\n",
      "\n",
      "Topic #3:\n",
      "teeth,water,use,ok,floss,waterpik,gum,easy,easy use,clean,dentist,mouth,flossing,one,dental\n",
      "\n",
      "Topic #4:\n",
      "nice,smell,scent,soap,deodorant,awesome,like,fragrance,bar,really,love,natural,strong,smell like,product\n",
      "\n",
      "Topic #5:\n",
      "perfect,beautiful,color,worth,love,love color,blush,needed,light,dark,coverage,worth money,well,shade,tone\n",
      "\n",
      "Topic #6:\n",
      "color,lip,lipstick,stay,pink,love,apply,like,red,nice,matte,look,liner,gloss,last\n",
      "\n",
      "Topic #7:\n",
      "work,work great,great,quality,good quality,look,good,worked,picture,worked great,bad,product work,like picture,look like,like\n",
      "\n",
      "Topic #8:\n",
      "money,didnt,waste,star,waste money,okay,didnt work,pretty,work,dont,horrible,5,product,poor,would\n",
      "\n",
      "Topic #9:\n",
      "excellent,described,arrived,item,exactly,came,received,order,broken,product,wanted,ordered,quickly,satisfied,time\n",
      "\n",
      "Topic #10:\n",
      "loved,gift,daughter,wife,love,bought,quality,great quality,wonderful,friend,great,christmas,son,husband,liked\n",
      "\n",
      "Topic #11:\n",
      "fine,eye,cheap,love stuff,stuff,lash,make,love,work,wax,use,stick,mascara,get,work fine\n",
      "\n",
      "Topic #12:\n",
      "hair,long,time,long time,last,last long,thick,product,curl,little,use,curly,iron,way,dry\n",
      "\n",
      "Topic #13:\n",
      "recommend,product,amazing,find,highly,highly recommend,excellent product,shipping,excellent,fast,store,would recommend,favorite,would,fast shipping\n",
      "\n",
      "Topic #14:\n",
      "using,product,week,result,difference,see,day,use,month,used,ive,im,skin,started,time\n",
      "\n",
      "Topic #15:\n",
      "well,work well,work,fit,job,small,size,made,doesnt,doesnt work,well made,high,travel,high quality,case\n",
      "\n",
      "Topic #16:\n",
      "expected,broke,advertised,good,good price,smaller,price,ear,work good,work,bigger,really good,really,nose,ring\n",
      "\n",
      "Topic #17:\n",
      "skin,face,product,dry,cream,feel,use,sensitive,love,great,make,dry skin,soft,smell,moisturizer\n",
      "\n",
      "Topic #18:\n",
      "great,great product,product,price,great price,thank,delivery,smell great,value,product great,service,fast,deal,smell,quick\n",
      "\n",
      "Topic #19:\n",
      "love,love product,hair,product,love love,shampoo,smell,love smell,soft,conditioner,make hair,make,body,wash,shiny\n",
      "\n",
      "Topic #20:\n",
      "like,really like,really,powder,cover,like product,product,feel,sponge,comfortable,foundation,work like,recommended,feel like,dont\n",
      "\n",
      "Topic #21:\n",
      "best,ever,used,ive,cant,tried,ever used,product,year,one,ive used,ive ever,many,wait,ive tried\n",
      "\n",
      "Topic #22:\n",
      "good,good product,oil,product,smell good,absolutely,smell,stuff,absolutely love,essential,product good,definitely,expectation,essential oil,far\n",
      "\n",
      "Topic #23:\n",
      "shaver,trimmer,one,battery,norelco,shave,charge,year,head,new,razor,model,replacement,use,beard\n",
      "\n",
      "Topic #24:\n",
      "wig,would,buy,review,know,dont,clip,hair,would buy,kid,like,product,one,dont know,received\n"
     ]
    }
   ],
   "source": [
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA:\")\n",
    "print_topics(lda, vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, these are the top words for each topic. The results are pretty good: we can see topics related to specific types of products like topic 2 (shaving), topic 3 (teeth) and topic 17 (skin). Other topics are related to logistics such as topic 9 and 13.\n",
    "\n",
    "There is a special package called LDAvis which allows us to visualize the topics. This gives the opportunity to take a deeper dive into the topics. For instance, in this package, we can adjust a relevance metric which allows us to rank terms of a topic according to their topic-specific probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lda_25.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving model to computer\n",
    "joblib.dump(lda,'lda_25.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this line if you need to load the model back into the notebook\n",
    "lda = joblib.load('lda_25.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize\n",
    "Let's use LDAvis to visualize the topics created from LDA topic modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant libraries\n",
    "from pyLDAvis import sklearn as sklearn_lda\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating file path\n",
    "LDAvis_data_filepath = os.path.join('./ldavis_prepared_'+str(number_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./ldavis_prepared_25'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDAvis_data_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ali_e\\Anaconda3\\envs\\test_env\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "# preparing the LDA model to be saved in the LDAvis visualizer\n",
    "LDAvis_prepared = sklearn_lda.prepare(lda, word_matrix, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving LDA model into LDAvis visualization\n",
    "with open(LDAvis_data_filepath, 'wb') as f:\n",
    "    pickle.dump(LDAvis_prepared, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving LDA model into LDAvis visualization html file\n",
    "pyLDAvis.save_html(LDAvis_prepared, './ldavis_prepared_'+ str(number_topics) +'.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now open the html file which contains the LDA visualization and take a deeper look into the topics and most relevant terms. An analysis of the terms will be provided in the final report.\n",
    "\n",
    "Please proceed to the next book in which cluster analysis of the KMeans model is performed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
